{"cells":[{"cell_type":"markdown","metadata":{"id":"1RNzl-GpDAPc"},"source":["<img src=\"https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png\" srcset=\"https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_130 130w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_260 260w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_390 390w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_520 520w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_650 650w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_780 780w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_910 910w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_1040 1040w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_1170 1170w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_1290 1290w\" sizes=\"100vw\" width=\"1290\">\n","\n","<p style='margin-top: 1rem; margin-bottom: 1rem;'>Developed by Sebastian Gingter, Developer Consultant @ <a href='https://thinktecture.com' _target='blank'>Thinktecture AG</a> -- More about me on my <a href='https://thinktecture.com/sebastian-gingter' _target='blank'>profile page</a></p>\n","\n","# Simple Chat with Message History\n","\n","In this lab, you'll implement a simple chat interface with message history using LangChain. The chat will:\n","\n","1. Maintain a history of all messages\n","2. Allow adding new messages\n","3. Use the history as context for responses\n","4. Store both user and AI messages in the conversation\n","\n","Tasks and details:\n","* All parts where you should implement something are marked with \"...\" or a sentence starting with \"Task: \"\n","* You'll implement a chat system that remembers context from previous messages\n","* The system must properly handle message history and use it for generating responses\n","* The chat should maintain a professional and helpful tone\n","\n","If you need help:\n","* Use the LangChain chat bot for anything about LangChain: https://chat.langchain.com/\n","* For general questions you can use free https://huggingface.co/chat/ with nvidia/Llama-3.1-Nemotron-70B-Instruct-HF LLM - you need a free HuggingFace account to login\n","* Look at the LangChain documentation for `RunnableWithMessageHistory` and `ChatMessageHistory`: https://python.langchain.com/docs/versions/migrating_memory/chat_history/#using-with-runnablewithmessagehistory"]},{"cell_type":"markdown","metadata":{"id":"-asV-GNgDAPd"},"source":["## Setup\n","\n","First, let's install the required packages and set up our environment:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OmJME2MvDAPd"},"source":["!pip install -q langchain==0.3.7 langchain-openai==0.2.5 langchain-community==0.3.5"],"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M4ajkeAsDAPe"},"source":["### Set API keys via Colab Secrets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oRcg_u0kDAPe"},"source":["import os\n","from google.colab import userdata\n","\n","# Set OVH API key\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get('OVH_AI_ENDPOINTS_ACCESS_TOKEN')"],"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d_7vLorZDAPe"},"source":["## Available LLMs\n","\n","OVH provides several LLM options. Choose one by uncommenting the desired model:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"25J0TXFbDAPe"},"source":["# Model configuration\n","TEMPERATURE = 0\n","MAX_TOKENS = 1500\n","\n","# OVH AI Endpoints Overview: https://endpoints.ai.cloud.ovh.net/\n","\n","# Task: Choose and uncomment one of the models below\n","\n","# OVH Mistral-7B-0.2\n","#MODEL_NAME = \"Mistral-7B-Instruct-v0.2\"\n","#BASE_URL = \"https://mistral-7b-instruct-v02.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1\"\n","\n","# OVH Mixtral 8x22B\n","#MODEL_NAME = \"Mixtral-8x22B-Instruct-v0.1\"\n","#BASE_URL = \"https://mixtral-8x22b-instruct-v01.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1\"\n","\n","# OVH Llama3-70B\n","#MODEL_NAME = \"Meta-Llama-3-70B-Instruct\"\n","#BASE_URL = \"https://llama-3-70b-instruct.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1\"\n","\n","# OVH Llama3-8B\n","#MODEL_NAME = \"Meta-Llama-3-8B-Instruct\"\n","#BASE_URL = \"https://llama-3-8b-instruct.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1\"\n","\n","# OVH Llama3.1-70B (default)\n","MODEL_NAME = \"Meta-Llama-3_1-70B-Instruct\"\n","BASE_URL = \"https://llama-3-1-70b-instruct.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1\""],"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z6kRH5QGDAPf"},"source":["## Initialize Chat Components\n","\n","Now we'll set up our chat model and message history:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RDD56tvVDAPf"},"source":["from langchain_openai import ChatOpenAI\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_community.chat_message_histories import ChatMessageHistory\n","from langchain_core.runnables.history import RunnableWithMessageHistory\n","\n","# Task: Initialize the chat model with OVH\n","chat = ...\n","\n","# Task: Create a prompt template with system message and placeholders for history and input\n","prompt = ...\n","\n","# Task: Create the basic chain\n","chain = ...\n","\n","# Task: Initialize message history\n","message_history = ...\n","\n","# Task: Create a chain with message history\n","chain_with_history = ..."],"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NL1yu11hDAPf"},"source":["## Chat Interface\n","\n","Let's create a simple function to handle chat interactions:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g696tJQuDAPf"},"source":["def chat_with_history(user_input: str):\n","    \"\"\"Send a message to the chat and get a response\"\"\"\n","    # Task: Implement the chat function that:\n","    # 1. Takes user input\n","    # 2. Sends it through the chain with history\n","    # 3. Prints the assistant's response\n","    # 4. Shows the current message history\n","    ..."],"outputs":[]},{"cell_type":"markdown","metadata":{"id":"80aOlXiNDAPg"},"source":["## Try it out!\n","\n","Let's test our chat with some example interactions:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OTJz92qgDAPg"},"source":["chat_with_history(\"Hi! My name is Alice.\")"],"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uOlyRJRFDAPg"},"source":["chat_with_history(\"What's my name?\")"],"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OPQA1LgmDAPg"},"source":["## Your Turn!\n","\n","Type your message in the cell below and run it to chat with the AI. The assistant will remember the context of your conversation:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eY68xtjKDAPg"},"source":["chat_with_history(\"Your message here\")"],"outputs":[]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}