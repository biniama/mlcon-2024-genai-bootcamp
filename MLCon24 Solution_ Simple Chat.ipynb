{"cells":[{"cell_type":"markdown","metadata":{"id":"WCigm_4gsRqP"},"source":["<img src=\"https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png\" srcset=\"https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_130 130w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_260 260w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_390 390w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_520 520w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_650 650w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_780 780w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_910 910w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_1040 1040w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_1170 1170w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_1290 1290w\" sizes=\"100vw\" width=\"1290\">\n","\n","<p style='margin-top: 1rem; margin-bottom: 1rem;'>Developed by Sebastian Gingter, Developer Consultant @ <a href='https://thinktecture.com' _target='blank'>Thinktecture AG</a> -- More about me on my <a href='https://thinktecture.com/sebastian-gingter' _target='blank'>profile page</a></p>\n","\n","# Simple Chat with Message History\n","\n","This notebook demonstrates how to create a simple chat interface with message history using LangChain. The chat will:\n","\n","1. Maintain a history of all messages\n","2. Allow adding new messages\n","3. Use the history as context for responses\n","4. Store both user and AI messages in the conversation\n","\n","Key concepts covered:\n","- Message history management\n","- Context-aware responses\n","- LangChain chat components\n","- OVH LLM integration"]},{"cell_type":"markdown","metadata":{"id":"nxta2VlVsRqR"},"source":["## Setup\n","\n","First, let's install the required packages and set up our environment:"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"_KVwuRvDsRqS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732539072005,"user_tz":-60,"elapsed":18295,"user":{"displayName":"Sebastian Gingter","userId":"03749202599653192620"}},"outputId":"7710e43d-349c-48d5-838b-e89c65f38b85"},"source":["!pip install -q langchain==0.3.7 langchain-openai==0.2.5 langchain-community==0.3.5"],"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/dataclasses-json/\u001b[0m\u001b[33m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","metadata":{"id":"Z7MQuotFsRqS"},"source":["### Set API keys via Colab Secrets"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"GrPKAJP4sRqS","executionInfo":{"status":"ok","timestamp":1732539073776,"user_tz":-60,"elapsed":1774,"user":{"displayName":"Sebastian Gingter","userId":"03749202599653192620"}}},"source":["import os\n","from google.colab import userdata\n","\n","# Set OVH API key\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get('OVH_AI_ENDPOINTS_ACCESS_TOKEN')"],"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4QCXx9dpsRqS"},"source":["## Available LLMs\n","\n","OVH provides several LLM options. We'll use Llama3.1-70B as our default model:"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"F_Gvp7RqsRqT","executionInfo":{"status":"ok","timestamp":1732539076624,"user_tz":-60,"elapsed":240,"user":{"displayName":"Sebastian Gingter","userId":"03749202599653192620"}}},"source":["# Model configuration\n","TEMPERATURE = 0\n","MAX_TOKENS = 1500\n","\n","# OVH AI Endpoints Overview: https://endpoints.ai.cloud.ovh.net/\n","\n","# OVH Llama3.1-70B (default)\n","MODEL_NAME = \"Meta-Llama-3_1-70B-Instruct\"\n","BASE_URL = \"https://llama-3-1-70b-instruct.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1\""],"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YWInVnbtsRqT"},"source":["## Initialize Chat Components\n","\n","Now we'll set up our chat model and message history:"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"VfPPaalGsRqT","executionInfo":{"status":"ok","timestamp":1732539090261,"user_tz":-60,"elapsed":4368,"user":{"displayName":"Sebastian Gingter","userId":"03749202599653192620"}}},"source":["from langchain_openai import ChatOpenAI\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_community.chat_message_histories import ChatMessageHistory\n","from langchain_core.runnables.history import RunnableWithMessageHistory\n","\n","# Initialize the chat model with OVH\n","chat = ChatOpenAI(\n","    model=MODEL_NAME,\n","    temperature=TEMPERATURE,\n","    max_tokens=MAX_TOKENS,\n","    base_url=BASE_URL\n",")\n","\n","# Create a prompt template\n","prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"You are a helpful assistant. Answer all questions to the best of your ability.\"),\n","    (\"placeholder\", \"{chat_history}\"),\n","    (\"human\", \"{input}\")\n","])\n","\n","# Create the basic chain\n","chain = prompt | chat\n","\n","# Initialize message history\n","message_history = ChatMessageHistory()\n","\n","# Create a chain with message history\n","chain_with_history = RunnableWithMessageHistory(\n","    chain,\n","    lambda session_id: message_history,\n","    input_messages_key=\"input\",\n","    history_messages_key=\"chat_history\"\n",")"],"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kfb8OgQSsRqU"},"source":["## Chat Interface\n","\n","Let's create a simple function to handle chat interactions:"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"UEbFiYGysRqU","executionInfo":{"status":"ok","timestamp":1732539353936,"user_tz":-60,"elapsed":224,"user":{"displayName":"Sebastian Gingter","userId":"03749202599653192620"}}},"source":["def chat_with_history(user_input: str):\n","    \"\"\"Send a message to the chat and get a response\"\"\"\n","    response = chain_with_history.invoke(\n","        {\"input\": user_input},\n","        {\"configurable\": {\"session_id\": \"demo\"}}\n","    )\n","\n","    print(f\"Assistant: {response.content}\")\n","    print(\"\\nCurrent message history:\")\n","    for msg in message_history.messages:\n","        print(f\"{msg.type.capitalize()}: {msg.content}\")"],"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jCpBgKi2sRqU"},"source":["## Try it out!\n","\n","Let's test our chat with some example interactions:"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"CcG3gQtWsRqU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732539364187,"user_tz":-60,"elapsed":1924,"user":{"displayName":"Sebastian Gingter","userId":"03749202599653192620"}},"outputId":"88358364-8e50-4f5d-d501-9c335bde8e2c"},"source":["chat_with_history(\"Hi! My name is Alice.\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["Assistant: Hello Alice, it's nice to meet you. Is there something I can help you with or would you like to chat?\n","\n","Current message history:\n","Human: Hi! My name is Alice.\n","Ai: Hello Alice, it's nice to meet you. Is there something I can help you with or would you like to chat?\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"id":"QyeR8PrgsRqU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732539377876,"user_tz":-60,"elapsed":925,"user":{"displayName":"Sebastian Gingter","userId":"03749202599653192620"}},"outputId":"f7239103-5c66-4b70-a5d8-140108ca3a65"},"source":["chat_with_history(\"What's my name?\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["Assistant: Your name is Alice.\n","\n","Current message history:\n","Human: Hi! My name is Alice.\n","Ai: Hello Alice, it's nice to meet you. Is there something I can help you with or would you like to chat?\n","Human: What's my name?\n","Ai: Your name is Alice.\n"]}]},{"cell_type":"markdown","metadata":{"id":"kim_0o7XsRqU"},"source":["## Your Turn!\n","\n","Type your message in the cell below and run it to chat with the AI. The assistant will remember the context of your conversation:"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Rfvc9kP5sRqV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732539388041,"user_tz":-60,"elapsed":1083,"user":{"displayName":"Sebastian Gingter","userId":"03749202599653192620"}},"outputId":"fca5662b-7af9-4b0e-e8b0-bf08da21e227"},"source":["chat_with_history(\"Your message here\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["Assistant: How can I assist you today, Alice?\n","\n","Current message history:\n","Human: Hi! My name is Alice.\n","Ai: Hello Alice, it's nice to meet you. Is there something I can help you with or would you like to chat?\n","Human: What's my name?\n","Ai: Your name is Alice.\n","Human: Your message here\n","Ai: How can I assist you today, Alice?\n"]}]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":0}