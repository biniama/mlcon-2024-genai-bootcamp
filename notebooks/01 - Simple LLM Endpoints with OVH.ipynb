{"cells":[{"cell_type":"markdown","metadata":{"id":"Vigmlask6ys0"},"source":["<img src=\"https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png\" srcset=\"https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_130 130w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_260 260w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_390 390w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_520 520w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_650 650w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_780 780w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_910 910w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_1040 1040w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_1170 1170w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_1290 1290w\" sizes=\"100vw\" width=\"1290\">\n","<p style='margin-top: 1rem; margin-bottom: 1rem;'>Developed by Marco Frodl, Principal Consultant for Generative AI @ <a href='https://go.mfr.one/tt-en' _target='blank'>Thinktecture AG</a> -- More about me on my <a href='https://go.mfr.one/marcofrodl-en' _target='blank'>profile page</a></p>"]},{"cell_type":"markdown","metadata":{"id":"lJy5wsZuHvXz"},"source":["## Prettify Colab Notebook outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xOA06-GRFTeK"},"outputs":[],"source":["from IPython.display import HTML, display\n","\n","def set_css():\n","  display(HTML('''\n","  <style>\n","    pre {\n","        white-space: pre-wrap;\n","    }\n","  </style>\n","  '''))\n","get_ipython().events.register('pre_run_cell', set_css)"]},{"cell_type":"markdown","metadata":{"id":"XUC6k6SzJE5a"},"source":["## Set API keys via Colab Secrets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Aj0mSvhyJI5"},"outputs":[],"source":["# import Colab Secrets userdata module\n","from google.colab import userdata\n","\n","# set LLM Api Key\n","import os\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get('OVH_AI_ENDPOINTS_ACCESS_TOKEN')\n","\n","# set Langfuse API keys\n","os.environ[\"LANGFUSE_PUBLIC_KEY\"] = userdata.get('LANGFUSE_PUBLIC_KEY')\n","os.environ[\"LANGFUSE_SECRET_KEY\"] = userdata.get('LANGFUSE_SECRET_KEY')"]},{"cell_type":"markdown","metadata":{"id":"6jh11ajrHjFC"},"source":["## Load libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pfrfCqwVVG_Y"},"outputs":[],"source":["!pip -q install langchain==0.3.7 langchain-openai==0.2.5 langchain-community==0.3.5\n","!pip -q install langfuse==2.53.3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wsfvcpLnQyw_"},"outputs":[],"source":["# let's check the imported versions of the most important libraries\n","!pip show langchain\n","!pip show langchain_openai\n","!pip show langchain_community\n","!pip show langfuse"]},{"cell_type":"markdown","metadata":{"id":"vOP866IZG87z"},"source":["## Prepare LangFuse"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gdG06ivx5xV1"},"outputs":[],"source":["# prepare Langfuse as debugging and tracing framework for our Generative AI application - never develop GenAI apps without that!\n","from langfuse.callback import CallbackHandler\n","from langfuse import Langfuse\n","\n","# Initialize CallbackHandler\n","lf_handler = CallbackHandler()\n","\n","# Initialize Langfuse\n","langfuse = Langfuse()"]},{"cell_type":"markdown","metadata":{"id":"PflymEKFgBBl"},"source":["## Prepare LLM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YJ3o8h7OgBBm"},"outputs":[],"source":["from langchain_openai import ChatOpenAI\n","\n","TEMPERATURE = 0\n","MAX_TOKENS = 1500\n","\n","# OVH AI Endpoints Overview: https://endpoints.ai.cloud.ovh.net/\n","\n","# OVH Mistral-7B-0.2\n","#MODEL_NAME = \"Mistral-7B-Instruct-v0.2\"\n","#BASE_URL = \"https://mistral-7b-instruct-v02.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1\"\n","\n","# OVH Mixtral 8x22B\n","#MODEL_NAME = \"Mixtral-8x22B-Instruct-v0.1\"\n","#BASE_URL = \"https://mixtral-8x22b-instruct-v01.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1\"\n","\n","# OVH Llama3-70B\n","#MODEL_NAME = \"Meta-Llama-3-70B-Instruct\"\n","#BASE_URL = \"https://llama-3-70b-instruct.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1\"\n","\n","# OVH Llama3-8B\n","#MODEL_NAME = \"Meta-Llama-3-8B-Instruct\"\n","#BASE_URL = \"https://llama-3-8b-instruct.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1\"\n","\n","# OVH Llama3.1-70B\n","MODEL_NAME = \"Meta-Llama-3_1-70B-Instruct\"\n","BASE_URL = \"https://llama-3-1-70b-instruct.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1\"\n","\n","# OVH Mamba Codestral 7B\n","#MODEL_NAME = \"mamba-codestral-7B-v0.1\"\n","#BASE_URL = \"https://mamba-codestral-7b-v0-1.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1/\"\n","\n","# OVH CodeLlama-13B\n","#MODEL_NAME = \"CodeLlama-13b-Instruct-hf\"\n","#BASE_URL = \"https://codellama-13b-instruct-hf.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1\"\n","\n","llm = ChatOpenAI(model=MODEL_NAME, temperature=TEMPERATURE, max_tokens=MAX_TOKENS, base_url=BASE_URL)\n","\n","response = llm.invoke(\"Hello, how are you?\")\n","print(response.content)"]},{"cell_type":"markdown","metadata":{"id":"rn4nosl8fMCy"},"source":["## Simple LLM chat call"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cXO6J-UJxedm"},"outputs":[],"source":["# pure as water\n","result = llm.invoke(\"How to code a Python command-line tool that takes a number and outputs the square result?\")\n","print(f\"--- {MODEL_NAME} ---\")\n","print(result.content)\n","print(result.response_metadata)"]},{"cell_type":"markdown","metadata":{"id":"V1noY3GTC0_W"},"source":["## Chat with Tracing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-rkMVTf3BoSQ"},"outputs":[],"source":["# lets optimize and trace whats happening\n","from langchain_core.messages import HumanMessage, SystemMessage\n","messages = [SystemMessage(content=\"Provide detailed, technically specific, and accurate responses. Assume the role of a knowledgeable AI assistant with expertise in Python development and generative AI. Offer comprehensive answers to technical questions, drawing from your in-depth understanding of Python programming and AI concepts. Share code examples, explain complex concepts, and provide actionable advice when relevant.\")]\n","messages.extend([HumanMessage(content=\"How to code a Python command-line tool that takes a number and outputs the square result?\")])\n","\n","result = llm.invoke(messages,{\"callbacks\":[lf_handler]})\n","print(f\"--- {MODEL_NAME} ---\")\n","print(result.content)\n","print(result.response_metadata)"]}],"metadata":{"colab":{"collapsed_sections":["lJy5wsZuHvXz"],"provenance":[{"file_id":"1TCha_WGuZRqnx-X306ONSa7zpGeI4xhg","timestamp":1732282978595},{"file_id":"1VIddcVmjpEC5Ju_oVEoLYAUahxsCmskb","timestamp":1730659476591},{"file_id":"1o3PbdmzBt_Hw47glh0ZMDWWtkpfle2Q8","timestamp":1728747398793},{"file_id":"1RJY2Iw1syFXQqskaW-trGSAK6TDw49os","timestamp":1727958136285},{"file_id":"1YW8tGacff05Ie7sSAtF7f6ItjA-l0R-B","timestamp":1727765579943},{"file_id":"14hP4Ld97QlJdWTBaHU2I2e0ZzMUw-WF-","timestamp":1727599529874},{"file_id":"1D2QriJvCzNUdU__n7VEWxebiYVnF1GwO","timestamp":1704649306386}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}