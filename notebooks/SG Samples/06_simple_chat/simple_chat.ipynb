{"cells":[{"cell_type":"markdown","metadata":{"id":"l9OeKYMVytQm"},"source":["<img src=\"https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png\" srcset=\"https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_130 130w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_260 260w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_390 390w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_520 520w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_650 650w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_780 780w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_910 910w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_1040 1040w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_1170 1170w, https://71022.cdn.cke-cs.com/RructTCFEHceQFc13ldy/images/6dbe93b28dbb43fbc9d50623b68a675a1fedd7608af93b46.png/w_1290 1290w\" sizes=\"100vw\" width=\"1290\">\n","\n","<p style='margin-top: 1rem; margin-bottom: 1rem;'>Developed by Sebastian Gingter, Developer Consultant @ <a href='https://thinktecture.com' _target='blank'>Thinktecture AG</a> -- More about me on my <a href='https://thinktecture.com/sebastian-gingter' _target='blank'>profile page</a></p>\n","\n","# Simple Chat with Message History\n","\n","This notebook demonstrates how to create a simple chat interface with message history using LangChain. The chat will:\n","1. Maintain a history of all messages\n","2. Allow adding new messages\n","3. Use the history as context for responses\n","4. Store both user and AI messages in the conversation"]},{"cell_type":"markdown","metadata":{"id":"xSp1irHkytQn"},"source":["## Setup\n","\n","First, let's install the required packages and set up our environment:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LbuiyM9EytQn"},"source":["!pip install -q langchain==0.3.7 langchain-openai==0.2.5 langchain-community==0.3.5\n","\n","import os\n","from google.colab import userdata\n","\n","# Set OVH API key\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get('OVH_AI_ENDPOINTS_ACCESS_TOKEN')"],"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KyQSA4PAytQn"},"source":["## Available LLMs\n","\n","OVH provides several LLM options. Choose one by uncommenting the desired model:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-rHCFKccytQo"},"source":["# Model configuration\n","TEMPERATURE = 0\n","MAX_TOKENS = 1500\n","\n","# OVH AI Endpoints Overview: https://endpoints.ai.cloud.ovh.net/\n","\n","# Uncomment the model you want to use:\n","\n","# OVH Mistral-7B-0.2\n","#MODEL_NAME = \"Mistral-7B-Instruct-v0.2\"\n","#BASE_URL = \"https://mistral-7b-instruct-v02.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1\"\n","\n","# OVH Mixtral 8x22B\n","#MODEL_NAME = \"Mixtral-8x22B-Instruct-v0.1\"\n","#BASE_URL = \"https://mixtral-8x22b-instruct-v01.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1\"\n","\n","# OVH Llama3-70B\n","#MODEL_NAME = \"Meta-Llama-3-70B-Instruct\"\n","#BASE_URL = \"https://llama-3-70b-instruct.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1\"\n","\n","# OVH Llama3-8B\n","#MODEL_NAME = \"Meta-Llama-3-8B-Instruct\"\n","#BASE_URL = \"https://llama-3-8b-instruct.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1\"\n","\n","# OVH Llama3.1-70B (default)\n","MODEL_NAME = \"Meta-Llama-3_1-70B-Instruct\"\n","BASE_URL = \"https://llama-3-1-70b-instruct.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1\"\n","\n","# OVH Mamba Codestral 7B\n","#MODEL_NAME = \"mamba-codestral-7B-v0.1\"\n","#BASE_URL = \"https://mamba-codestral-7b-v0-1.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1/\"\n","\n","# OVH CodeLlama-13B\n","#MODEL_NAME = \"CodeLlama-13b-Instruct-hf\"\n","#BASE_URL = \"https://codellama-13b-instruct-hf.endpoints.kepler.ai.cloud.ovh.net/api/openai_compat/v1\""],"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TXT1pObjytQo"},"source":["## Initialize Chat Components\n","\n","Now we'll set up our chat model and message history:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Q2EMfaEytQo"},"source":["from langchain_openai import ChatOpenAI\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_community.chat_message_histories import ChatMessageHistory\n","from langchain_core.runnables.history import RunnableWithMessageHistory\n","\n","# Initialize the chat model with OVH\n","chat = ChatOpenAI(\n","    model=MODEL_NAME,\n","    temperature=TEMPERATURE,\n","    max_tokens=MAX_TOKENS,\n","    base_url=BASE_URL\n",")\n","\n","# Create a prompt template\n","prompt = ChatPromptTemplate.from_messages([\n","    (\"system\", \"You are a helpful assistant. Answer all questions to the best of your ability.\"),\n","    (\"placeholder\", \"{chat_history}\"),\n","    (\"human\", \"{input}\")\n","])\n","\n","# Create the basic chain\n","chain = prompt | chat\n","\n","# Initialize message history\n","message_history = ChatMessageHistory()\n","\n","# Create a chain with message history\n","chain_with_history = RunnableWithMessageHistory(\n","    chain,\n","    lambda session_id: message_history,\n","    input_messages_key=\"input\",\n","    history_messages_key=\"chat_history\"\n",")"],"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HCXVaQ4WytQo"},"source":["## Chat Interface\n","\n","Let's create a simple function to handle chat interactions:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5tHec8i9ytQp"},"source":["def chat_with_history(user_input: str):\n","    \"\"\"Send a message to the chat and get a response\"\"\"\n","    response = chain_with_history.invoke(\n","        {\"input\": user_input},\n","        {\"configurable\": {\"session_id\": \"demo\"}}\n","    )\n","\n","    print(f\"Assistant: {response.content}\")\n","    print(\"\\nCurrent message history:\")\n","    for msg in message_history.messages:\n","        print(f\"{msg.type.capitalize()}: {msg.content}\")"],"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-ryZtyexytQp"},"source":["## Try it out!\n","\n","Let's test our chat with some example interactions:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ImfC1ljPytQp"},"source":["chat_with_history(\"Hi! My name is Alice.\")"],"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u9Lub2N-ytQp"},"source":["chat_with_history(\"What's my name?\")"],"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NyssD-W-ytQp"},"source":["## Your Turn!\n","\n","Type your message in the cell below and run it to chat with the AI. The assistant will remember the context of your conversation:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SMHJtJ5NytQp"},"source":["chat_with_history(\"Your message here\")"],"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}